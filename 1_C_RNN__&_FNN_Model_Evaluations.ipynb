{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "znADidWr146q"
      },
      "outputs": [],
      "source": [
        "# 4. Model Evaluation:\n",
        "# Evaluate the models on the test set using metrics like accuracy, precision, recall, F1-score, ROC AUC, etc.\n",
        "# Compare the performance of different models to choose the best one."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feedforward Neural Networks (FNN) Model Evaluation\n",
        "# Predict on the validation set\n",
        "y_pred = (fnn_model.predict(X_val_preprocessed) > 0.5).astype(\"int32\")\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "precision = precision_score(y_val, y_pred)\n",
        "recall = recall_score(y_val, y_pred)\n",
        "f1 = f1_score(y_val, y_pred)\n",
        "roc_auc = roc_auc_score(y_val, y_pred)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"Feedforward Neural Networks (FNN) Model Performance: \")\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"ROC AUC Score:\", roc_auc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqzUWLewZ6_6",
        "outputId": "24fac147-3eeb-4262-9528-5e2f0a256aeb"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 0s 2ms/step\n",
            "Feedforward Neural Networks (FNN) Model Performance: \n",
            "Accuracy: 0.8785607196401799\n",
            "Precision: 0.65625\n",
            "Recall: 0.4158415841584158\n",
            "F1 Score: 0.509090909090909\n",
            "ROC AUC Score: 0.6884861631039428\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the probabilities of churn for the validation data\n",
        "y_val_pred_proba = rnn_model.predict(X_val_sequences)\n",
        "\n",
        "# Convert probabilities to binary predictions (0 or 1) based on a threshold (e.g., 0.5)\n",
        "y_val_pred = (y_val_pred_proba > 0.5).astype(int)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_val_trimmed, y_val_pred)\n",
        "precision = precision_score(y_val_trimmed, y_val_pred)\n",
        "recall = recall_score(y_val_trimmed, y_val_pred)\n",
        "f1 = f1_score(y_val_trimmed, y_val_pred)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"Recurrent Neural Networks (RNN) Model Performance: \")\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBcIUt4kV5Gs",
        "outputId": "2087a14b-44af-49a4-ed74-81a8d5268d4f"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 0s 4ms/step\n",
            "Recurrent Neural Networks (RNN) Model Performance: \n",
            "Accuracy: 0.8753799392097265\n",
            "Precision: 0.8\n",
            "Recall: 0.24\n",
            "F1-score: 0.36923076923076925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluations for both a Feedforward Neural Network (FNN) model and a Recurrent Neural Network (RNN) model.\n",
        "# Let's compare their performance and discuss the differences:\n",
        "\n",
        "# Performance Comparison:\n",
        "\n",
        "# Feedforward Neural Network (FNN) Model:\n",
        "# Accuracy: 0.8786\n",
        "# Precision: 0.6563\n",
        "# Recall: 0.4158\n",
        "# F1 Score: 0.5091\n",
        "# ROC AUC Score: 0.6885\n",
        "\n",
        "# Recurrent Neural Network (RNN) Model:\n",
        "# Accuracy: 0.8754\n",
        "# Precision: 0.8000\n",
        "# Recall: 0.2400\n",
        "# F1 Score: 0.3692\n",
        "\n",
        "\n",
        "# # Analysis:\n",
        "\n",
        "# Accuracy:\n",
        "\n",
        "# The FNN model has a slightly higher accuracy than the RNN model. However, the difference is marginal.\n",
        "\n",
        "# Precision and Recall:\n",
        "\n",
        "# The FNN model has lower precision but higher recall compared to the RNN model.\n",
        "# This suggests that the FNN model is better at identifying true positives (churn instances) but also has more false positives,\n",
        "#  whereas the RNN model has fewer false positives but also misses more churn instances.\n",
        "\n",
        "# F1 Score:\n",
        "\n",
        "# The F1 score for the FNN model is higher than that of the RNN model, indicating a better balance between precision and recall.\n",
        "\n",
        "# ROC AUC Score:\n",
        "\n",
        "# The ROC AUC score for the FNN model is slightly higher than that of the RNN model,\n",
        "#  suggesting better overall performance in terms of ranking predictions"
      ],
      "metadata": {
        "id": "_YDo2ScPbANS"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recommendations and Considerations:\n",
        "\n",
        "# Model Selection:\n",
        "# Both models have their strengths and weaknesses. If the application requires a balance between precision and recall;\n",
        "# the FNN model might be preferred due to its higher F1 score.\n",
        "# However, if minimizing false positives is crucial, the RNN model's higher precision could be advantageous.\n",
        "\n",
        "\n",
        "# Data Size:\n",
        "# It's essential to consider the size of the dataset. Typically, RNNs perform better with sequential data\n",
        "# and might outperform FNNs on larger datasets with intricate temporal dependencies.\n",
        "\n",
        "\n",
        "# Fine-tuning:\n",
        "\n",
        "# Both models could benefit from fine-tuning. Techniques such as hyperparameter tuning, adjusting network architecture,\n",
        "# or incorporating regularization methods like dropout or L2 regularization can help improve performance.\n",
        "\n",
        "# Feature Engineering:\n",
        "# Analyzing the features used in both models could provide insights into which features are most informative for churn prediction.\n",
        "# Feature engineering, including feature selection, extraction, or transformation, might enhance model performance.\n",
        "\n",
        "# NB:  Ensemble Methods:\n",
        "# Ensemble techniques like model averaging or stacking could be explored to combine predictions from both models,\n",
        "# potentially leveraging the strengths of each for improved overall performance."
      ],
      "metadata": {
        "id": "_22-HTW6boZi"
      },
      "execution_count": 202,
      "outputs": []
    }
  ]
}