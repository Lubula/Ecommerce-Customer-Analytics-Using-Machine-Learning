{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "znADidWr146q"
      },
      "outputs": [],
      "source": [
        "# Feedforward Neural Networks (FNN):\n",
        "# Design a Feedforward Neural Network architecture. we will Use libraries like TensorFlow or PyTorch to build and train your model.\n",
        "# Define the input layer according to the number of features.\n",
        "# Design hidden layers with appropriate activation functions (e.g., ReLU) and units.\n",
        "# Define the output layer. Since it's a binary classification problem (churn prediction),\n",
        "# we use a sigmoid activation function in the output layer.\n",
        "\n",
        "# 2. Model Training:\n",
        "# Compile the models with appropriate loss functions (e.g., binary cross-entropy) and optimizers (e.g., Adam).\n",
        "# Train the models on the training data.\n",
        "# Monitor performance on the validation set to avoid overfitting.\n",
        "# Tweak hyperparameters if necessary.\n",
        "\n",
        "# 4. Model Evaluation:\n",
        "# Evaluate the models on the test set using metrics like accuracy, precision, recall, F1-score, ROC AUC, etc.\n",
        "# Compare the performance of different models to choose the best one."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from scipy.sparse import issparse\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n"
      ],
      "metadata": {
        "id": "JCVsHOIq3cp5"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feedforward Neural Networks (FNN) Model Evaluation\n",
        "# Predict on the validation set\n",
        "y_pred = (fnn_model.predict(X_val_preprocessed) > 0.5).astype(\"int32\")\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "precision = precision_score(y_val, y_pred)\n",
        "recall = recall_score(y_val, y_pred)\n",
        "f1 = f1_score(y_val, y_pred)\n",
        "roc_auc = roc_auc_score(y_val, y_pred)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"ROC AUC Score:\", roc_auc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0m_ECVXUES4q",
        "outputId": "650ebe45-6ed3-4329-c7df-fb2af77e3f7b"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 0s 3ms/step\n",
            "Accuracy: 0.8785607196401799\n",
            "Precision: 0.65625\n",
            "Recall: 0.4158415841584158\n",
            "F1 Score: 0.509090909090909\n",
            "ROC AUC Score: 0.6884861631039428\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# saving model to be run and improved later\n",
        "# import pickle\n",
        "\n",
        "# Save the model using pickle\n",
        "# with open(\"fnn_model.pkl\", \"wb\") as f:\n",
        "#    pickle.dump(fnn_model, f)\n",
        "\n",
        "# Optionally, you can load the saved model later\n",
        "# with open(\"fnn_model.pkl\", \"rb\") as f:\n",
        "#     loaded_model = pickle.load(f)"
      ],
      "metadata": {
        "id": "hNQRkmI6FD6t"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we have saved the model\n",
        "# now lets create the function so that we can recall the model and run it on new client data:\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "def load_and_predict(new_data_path, saved_model_path):\n",
        "    # Load new data\n",
        "    new_data = pd.read_csv(new_data_path, sep=';') # where the data is stored loacally\n",
        "\n",
        "    # Preprocess the new data\n",
        "    X_new = new_data.drop(columns=['churn'])\n",
        "    preprocessor = load_model(saved_model_path + \"_preprocessor\")  # Load preprocessor\n",
        "    X_new_preprocessed = preprocessor.transform(X_new)\n",
        "\n",
        "    # Load the saved model\n",
        "    model = load_model(saved_model_path)\n",
        "\n",
        "    # Predict churn\n",
        "    predictions = (model.predict(X_new_preprocessed) > 0.5).astype(\"int32\")\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# Example usage\n",
        "new_data_path = \"path/to/new_data.csv\"\n",
        "saved_model_path = \"path/to/saved_model.h5\"\n",
        "predictions = load_and_predict(new_data_path, saved_model_path)\n",
        "print(\"Predictions:\", predictions)\n"
      ],
      "metadata": {
        "id": "8w7jlauwPK3b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
